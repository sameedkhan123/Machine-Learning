{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Full_COVID_19_Detection_using_Capsules.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qx7JaoSKLiXY",
        "aK4rriSrK_Th",
        "itW4FHefngyR",
        "OImdqetR5qvP",
        "kKymZr33L5GP",
        "JvAL2n7mTQxH",
        "_NeXvl5zvN35",
        "YAFqqTWptCFG",
        "G270NFAKqQM2",
        "cxMXPg-lEUwY",
        "MCfEqYV-XddX",
        "GwDCKAXTX1uu",
        "rKcv72z8wM5I",
        "1tB-3Nay-Mw7",
        "g_08KPpP-MUG",
        "9yCXONJ--XTm",
        "zCLOggS8-XyE",
        "3Gw-npAl_ort",
        "cnO_LbzM_vGP",
        "Jumdc0D62A6Y",
        "CKcwuE1PAA9G",
        "cV2xBIMyAHD8",
        "X0KFJM1qANyu",
        "LB8bTGYWAyEJ",
        "tks-Vx41A26i",
        "vmbgk_UJA-vi",
        "TGsa3JpsBGKb",
        "CRnDy9VPBMUc",
        "nNsIqoaa5sO8",
        "1mk0ooYI5vvY",
        "Sg9NFk9u5zxH",
        "XuUREJLMnaJr",
        "7o_OGVu8pSzI",
        "LCv7tZo9pZLY",
        "TwdfOw5vsWQ8",
        "c6tSt4D5pjlX",
        "0Nb5J-Fvpofs",
        "VrkQlTxstt_e",
        "bRCJA1dMp0fz",
        "YRTs8_m8p5xY",
        "9faFfHMxt_3J",
        "HZyBK-xYwrHY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX1KBaGT7qZm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv2y9TFhubxO"
      },
      "source": [
        "<br><br><br>\n",
        "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
        "<center> <h3 style=\"color:green\">In the Name of Allah, the Most Beneficent, the Most Merciful</h3> </center>\n",
        "<center> <h3 style=\"color:blue\">========================================================</h3> </center>\n",
        "<br><br><br>\n",
        "\n",
        "\n",
        "\n",
        "        *----------------------------- AUTHOR_DETAILS -------------------------------*\n",
        "        |                                                                            |\n",
        "        |        Project Title  = COVID-19 Detection Prediction System               |\n",
        "        |                                                                            |\n",
        "        |        Author         = Sameed Khan                                      |\n",
        "        |\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t     |\n",
        "        |        Co-Author      = Muhammad Hashir Khan\t\t\t\t\t\t\t\t |\n",
        "        |                                                                            |\n",
        "        |        Copyright      = Copyright (C) 2020 Farhan Shahid                   |\n",
        "        |                                                                            |\n",
        "        |        License        = Public Domain                                      |\n",
        "        |                                                                            |\n",
        "        |        Version        = 1.0                                                |\n",
        "        |                                                                            |\n",
        "        *----------------------------------------------------------------------------*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "<br/>\n",
        "<center><h3>\n",
        "Project Title\n",
        "Developing a COVID-19 Prediction System  (from X-ray Images) using Deep Neural Networks \n",
        "    </h3></center>\n",
        "\n",
        "\n",
        "<center><h3>Project Purpose</h3></center>\n",
        "<br />\n",
        "\n",
        "<h4>\n",
        "The main purpose of this Project is to demonstrate how Deep Neural Network can be used for the development and evaluation of COVID-19 Prediction System (from X-ray Images). For this purpose, In sha Allah, I will treat COVID-19  Prediction Problem as a Binary Classificaiton Problem i.e. the main goal is to discriminate between two Classses: (1) Normal and (2) Covid. In sha Allah, in the next Section, I will execute the Machine Learning Cycle.</h4>\n",
        "\n",
        "<br /><br /><br />\n",
        "* Input\n",
        "    *  Image\n",
        "* Outpu\n",
        "    * Label (Covid /Normal)\n",
        "\n",
        "**NOTE: FEATURES ARE EXTRACTED FROM INPUT**\\\n",
        "\n",
        "Steps – Executing Machine Learning Cycle \\\n",
        "Step 01: Import Libraries\\\n",
        "Step 02: Load Training Data, Testing Data and Validation Data\\\n",
        "    * Step 2.1: Load Training Data\\\n",
        "\t  * Step 2.2: Load Testing Data\t\\\n",
        "\t  * Step 2.3: Load Validation Data\\\n",
        "\n",
        "Step 03: Understand and Pre-process Training Data, Testing Data and Validation Data\\\n",
        "\t* Step 3.1: Understand Training Data\\\n",
        "\t* Step 3.2: Understand Testing Data\\\n",
        "\t* Step 3.3: Understand Validation Data\\\n",
        "\t* Step 3.4: Pre-process Training Data\n",
        "\t\t* Step 3.4.1: Resize X-ray Images in Training Data\\\n",
        "\t\t* Step 3.4.2: Convert Resized X-ray Images in Training Data into grayscale\\\n",
        "\t* Step 3.5: Pre-process Testing Data\\\n",
        "\t\t* Step 3.5.2: Convert Resized X-ray Images in Testing Data into grayscale\\\n",
        "\t* Step 3.6: Pre-process Validation Data\\\n",
        "\t\t* Step 3.6.1: Resize X-ray Images in Validation Data\\\n",
        "\t\t* Step 3.6.2: Convert Resized X-ray Images in Validation Data into grayscale\\\n",
        "\n",
        "Step 04: Represent Training Data, Testing Data and Validation Data in Numerical Representation (Machine Understandable Format)\\\n",
        "\t* Step 4.1: Represent Training Data into Machine Understandable Format\\\n",
        "\t\t* Step 4.1.1: Convert Resized Grayscale X-ray Images in Training Data into Numpy Array\\\n",
        "\t\t* Step 4.1.2: Nomalize Numpy Array of Grayscale X-ray Images in Training Data\\\n",
        "\t* Step 4.2: Represent Testing Data into Machine Understandable Format\\\n",
        "\t\t* Step 4.2.1: Convert Resized Grayscale X-ray Images in Testing Data into Numpy Array\\\n",
        "\t\t* Step 4.2.2: Nomalize Numpy Array of Grayscale X-ray Images in Testing Data\\\n",
        "\t* Step 4.3: Represent Validation Data into Machine Understandable Format\\\n",
        "\t\t* Step 4.3.1: Convert Resized Grayscale X-ray Images in Validation Data into Numpy Array\\\n",
        "\t\t* Step 4.3.2: Nomalize Numpy Array of Grayscale X-ray Images in Validation Data\\\n",
        "\n",
        "Step 05: Execute the Training Phase\\\n",
        "\t* Step 5.1: Create CNN Model Architecture\\\n",
        "\t* Step 5.2: Hyperparameters Settings\\\n",
        "\t* Step 5.3: Create CNN Model Object\\\n",
        "\t* Step 5.4: Initialize Optimizer and Loss Function\\\n",
        "\t* Step 5.5: Evaluation Measure\\\n",
        "\t* Step 5.6: Calculate Epoch Elapsed Time\\\n",
        "\t* Step 5.7: Train Model\\\n",
        "\t* Step 5.8: Save Model\\\n",
        "\n",
        "Step 06: Execute the Testing Phase\\\n",
        "\t* Step 6.1: Load Saved Model (Saved in Step 5.8)\\\n",
        "\t* Step 6.2: Make Predictions on Testing Data\\\n",
        "\t* Step 6.3: Evaluate Performance of Trained Model on Test Data\\\n",
        "\t\t* Step 6.3.1: Calculate Accuracy\\\n",
        "\t\t* Step 6.3.2: Draw Confusion Matrix\\\n",
        "\t\t* Step 6.3.3: Print Classification Report\\\n",
        "\n",
        "Step 07: Execute the Application Phase\\\n",
        "\t* Step 7.1: Take Input (X-ray Image) from User \\\n",
        "\t* Step 7.2: Convert User Input (X-ray Image) into Feature Vector (Exactly Same as Feature Vectors of Training Data, Testing Data and Validation Data)\\\n",
        "\t* Step 7.3: Make Prediction on Unseen Data\\\n",
        "\t\t* Step 7.3.1: Load the Model (Saved in Step 5.8)\\\n",
        "\t\t* Step 7.3.2: Apply Model on Feature Vector of Unseen Data\\\n",
        "\t\t* Step 7.3.3: Return Prediction to the User\\\n",
        "Step 08: Execute the Feedback Phase\\\n",
        "Step 09: Improve Model Based on Feedback\\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxpuQNpGKYSC"
      },
      "source": [
        "## Step 00: Enviroment Setup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipnz2EkrKfPz",
        "outputId": "aacecf24-f3d2-4d89-9f96-b82a53c2e6ea"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "# !pip uninstall keras==2.2.4\n",
        "!pip install keras==2.2.4\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 96kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.19.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.4.0)\n",
            "Installing collected packages: keras-applications, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.19.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.2.4\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=1c7d4c80525053669dc7fdb5725529b62e225174c8d556b18d717ff8f2164e15\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36w8GFNKKlhj"
      },
      "source": [
        "### Step 00: Verify Enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quVmVU_bKpun",
        "outputId": "49e2a019-43bd-4d7a-da7a-7771b4aaa657"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpsBmHsWnPQq"
      },
      "source": [
        "## Step 01: Import Libraries "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx7JaoSKLiXY"
      },
      "source": [
        "### Step: 1.1: Import 3rd Party Libraries through import keyword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmo5GdZznDgX",
        "outputId": "409ae578-d8d3-4aa5-f736-392fcd89bd59"
      },
      "source": [
        "import os # For OS Operation \n",
        "from os.path import join #Path Join\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "\n",
        "from keras.preprocessing.image import array_to_img\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras import layers, models, optimizers,initializers\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Input, Reshape, Layer, Lambda\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import random as my_random # For Selecting Random data\n",
        "\n",
        "%pylab inline\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#import wget\n",
        "\n",
        "from tqdm import tqdm # For Progressbar \n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK4rriSrK_Th"
      },
      "source": [
        "### Step 1.2: Import Custom Libraries Through Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLcfONj41EQd"
      },
      "source": [
        "def squash(output_vector, axis=-1):\n",
        "  norm = tf.reduce_sum(tf.square(output_vector), axis, keep_dims=True)\n",
        "  return output_vector * norm / ((1 + norm) * tf.sqrt(norm + 1.0e-10))\n",
        "\n",
        "class MaskingLayer(Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        input, mask = inputs\n",
        "        return K.batch_dot(input, mask, 1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        *_, output_shape = input_shape[0]\n",
        "        return (None, output_shape)\n",
        "  \n",
        "def PrimaryCapsule(n_vector, n_channel, n_kernel_size, n_stride, padding='valid'):\n",
        "    def builder(inputs):\n",
        "        output = Conv2D(filters=n_vector * n_channel, kernel_size=n_kernel_size, strides=n_stride, padding=padding)(inputs)\n",
        "        output = Reshape( target_shape=[-1, n_vector], name='primary_capsule_reshape')(output)\n",
        "        return Lambda(squash, name='primary_capsule_squash')(output)\n",
        "    return builder\n",
        "\n",
        "class CapsuleLayer(Layer):\n",
        "    def __init__(self, n_capsule, n_vec, n_routing, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.n_capsule = n_capsule\n",
        "        self.n_vector = n_vec\n",
        "        self.n_routing = n_routing\n",
        "        self.kernel_initializer = initializers.get('he_normal')\n",
        "        self.bias_initializer = initializers.get('zeros')\n",
        "\n",
        "    def build(self, input_shape): # input_shape is a 4D tensor\n",
        "        _, self.input_n_capsule, self.input_n_vector, *_ = input_shape\n",
        "        self.W = self.add_weight(shape=[self.input_n_capsule, self.n_capsule, self.input_n_vector, self.n_vector], initializer=self.kernel_initializer, name='W')\n",
        "        self.bias = self.add_weight(shape=[1, self.input_n_capsule, self.n_capsule, 1, 1], initializer=self.bias_initializer, name='bias', trainable=False)\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_expand = tf.expand_dims(tf.expand_dims(inputs, 2), 2)\n",
        "        input_tiled = tf.tile(input_expand, [1, 1, self.n_capsule, 1, 1])\n",
        "        input_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]), elems=input_tiled, initializer=K.zeros( [self.input_n_capsule, self.n_capsule, 1, self.n_vector]))\n",
        "        for i in range(self.n_routing): # routing\n",
        "            c = tf.nn.softmax(self.bias, dim=2)\n",
        "            outputs = squash(tf.reduce_sum( c * input_hat, axis=1, keep_dims=True))\n",
        "            if i != self.n_routing - 1:\n",
        "                self.bias += tf.reduce_sum(input_hat * outputs, axis=-1, keep_dims=True)\n",
        "        return tf.reshape(outputs, [-1, self.n_capsule, self.n_vector])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        # output current layer capsules\n",
        "        return (None, self.n_capsule, self.n_vector)\n",
        "\n",
        "    def get_config(self):\n",
        "      # For serialization with 'custom_objects'\n",
        "      config = super().get_config()\n",
        "      config['n_capsule'] = self.n_capsule\n",
        "      config['n_vec'] = self.n_vector\n",
        "      config['n_routing'] = self.n_routing\n",
        "      return config\n",
        "        \n",
        "    # def get_config(self):\n",
        "    #   config = {\n",
        "    #         'n_capsule': self.n_capsule,\n",
        "    #         'n_vec': self.n_vector,\n",
        "    #         'n_routing': self.n_routing\n",
        "    #     }\n",
        "    #   base_config = super(CapsuleLayer, self).get_config()\n",
        "    #   return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "class LengthLayer(Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1, keep_dims=False))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        *output_shape, _ = input_shape\n",
        "        return tuple(output_shape)\n",
        "\n",
        "\n",
        "def margin_loss(y_ground_truth, y_prediction):\n",
        "    _m_plus = 0.9\n",
        "    _m_minus = 0.1\n",
        "    _lambda = 0.5\n",
        "    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIoAXR7bL97c"
      },
      "source": [
        "### Step 1.3: Set Global Variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqxFm2ltoJ5Y"
      },
      "source": [
        "ROOT = \"/content/drive\"\n",
        "PROJ_NAME = \"Covid\"\n",
        "PROJ_FOLDER = \"My Drive/Colab Notebooks/ML\"\n",
        "PROJECT_PATH = join(ROOT, PROJ_FOLDER,PROJ_NAME)\n",
        "DATASETS_PATH = join(PROJECT_PATH, \"Datasets\")\n",
        "MODEL_PATH = join(PROJECT_PATH, \"Model\")\n",
        "\n",
        "DATASET_PATH = join(DATASETS_PATH, 'Full_Dataset')\n",
        "\n",
        "XRAY_IMAGES_PATH = join(DATASET_PATH,\"X-RAY\")\n",
        "XRAY_HDF_PATH = join(DATASET_PATH,\"Covid19_Xray_Dataset.h5\")\n",
        "\n",
        "TRAINING_FOLDER = join(DATASET_PATH, \"Training\")\n",
        "VALIDATION_FOLDER = join(DATASET_PATH, \"Validation\")\n",
        "TESTING_FOLDER = join(DATASET_PATH, \"Testing\")\n",
        "\n",
        "TEST_IMAGE_PATH_1 = join(TESTING_FOLDER, \"89-Non-Covid.png\")\n",
        "TEST_IMAGE_PATH_2 = join(TESTING_FOLDER, \"95-Covid.png\")\n",
        "\n",
        "DATASET_DOWNLOAD_URL = \"https://github.com/ieee8023/covid-chestxray-dataset/archive/master.zip\"\n",
        "\n",
        "IMG_WIDTH = 64\n",
        "IMG_HEIGHT = 64\n",
        "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
        "\n",
        "\n",
        "NUM_ROUTING = 3\n",
        "INPUT_SHAPE = [IMG_WIDTH, IMG_HEIGHT, 1]\n",
        "EPOCH = 10\n",
        "TRAINING_BATCH_SIZE = 20\n",
        "TESTING_BATCH_SIZE = 10\n",
        "LEARNING_RATE = 0.001\n",
        "OPTIMIZER = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
        "#LOSSES = tf.keras.losses.BinaryCrossentropy()\n",
        "#OPTIMIZER = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
        "#LOSSES = [margin_loss]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itW4FHefngyR"
      },
      "source": [
        "## Step 02: Load Training Data, Testing Data and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OImdqetR5qvP"
      },
      "source": [
        "### Step 2.1: Download Dataset, Save Into Google Drive & Unzip "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKHgjSCT6atN"
      },
      "source": [
        "def download_dataset(dataset_path=DATASET_PATH):\n",
        "\n",
        "  if not os.path.isdir(dataset_path):\n",
        "    raise ValueError('Invalid directory path => {}'.format(dataset_path))\n",
        "  else:\n",
        "    full_dataset_path = join(DATASET_PATH,'master.zip') # Zip File Name given by me\n",
        "\n",
        "  if not os.path.isfile(full_dataset_path):\n",
        "    print(\"1. Downloading Dataset from => {}\\n\".format(DATASET_DOWNLOAD_URL))\n",
        "    save_path = wget.download(DATASET_DOWNLOAD_URL, full_dataset_path)\n",
        "    print(\"2. Dataset Saved in Google Drive at => {}\\n\".format(save_path))\n",
        "\n",
        "    print(\"3. Unziping Downloaded Dataset\\n\")\n",
        "    !unzip -q \"$save_path\" -d \"$DATASET_PATH\"\n",
        "    #List Directory\n",
        "    dir_names = !ls \"$DATASET_PATH\"\n",
        "    unzip_path = join(DATASET_PATH, str(dir_names[0]).split()[0])\n",
        "    print(\"Unziping Downloaded Dataset path => {}\".format(unzip_path))\n",
        "  else:\n",
        "    print(\"Unziping Downloaded Dataset\\n\")\n",
        "    !unzip -q \"$full_dataset_path\" -d \"$DATASET_PATH\"\n",
        "    #List Directory\n",
        "    dir_names = !ls \"$DATASET_PATH\"\n",
        "    unzip_path = join(DATASET_PATH, str(dir_names[0]).split()[0])\n",
        "    print(\"Unziping Downloaded Dataset path => {}\".format(unzip_path))\n",
        "  \n",
        "  return unzip_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "o67kiI9pChIs",
        "outputId": "e84fb1b6-cb81-4b42-de9d-343cbda1cc11"
      },
      "source": [
        "unzip_dataset_path = download_dataset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ac605b714369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munzip_dataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-af764aea7408>\u001b[0m in \u001b[0;36mdownload_dataset\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid directory path => {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfull_dataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'master.zip'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Zip File Name given by me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid directory path => /content/drive/My Drive/Colab Notebooks/ML/Covid/Datasets/Full_Dataset"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKymZr33L5GP"
      },
      "source": [
        "### Step 2.2: Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM5SpcpXUtvv"
      },
      "source": [
        "#### Step 2.2.1: Read CSV & Show top 3 Records with all coumns "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inw2TwVIL4Dt"
      },
      "source": [
        "# Read CSV\n",
        "meta_data = pd.read_csv(join(unzip_dataset_path, \"metadata.csv\"))\n",
        "# Display All columns\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "# Read First 3 Rows \n",
        "meta_data.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvAL2n7mTQxH"
      },
      "source": [
        "#### Step 2.2.2: Dataset Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6zfSjKxTRdI"
      },
      "source": [
        "def Get_Dataset_Summary(df, unique_count):\n",
        "    print(\n",
        "        \"\"\"\n",
        "Instance Space Columns List \n",
        "==========================\n",
        "{}\n",
        "        \n",
        "Instance Space Columns Count\n",
        "===========================\n",
        "{}\n",
        "        \n",
        "Instance Space Row Count\n",
        "==========================\n",
        "{}\n",
        "        \n",
        "Instance Space attribute value pair \n",
        "===================================\n",
        "        \"\"\".format(\n",
        "            df.columns,\n",
        "            len(df.columns),\n",
        "            len(df)\n",
        "        ))\n",
        "    \n",
        "    for col in df.columns: \n",
        "      if len(df[col].unique()) < unique_count:\n",
        "        print(\"#\"*50)\n",
        "        print(\"{}: {}\".format(col,list(df[col].unique())))\n",
        "        \n",
        "        print(\n",
        "            \"\"\"\n",
        "Distribution of each value in '{}' attribute\n",
        "=================================================\n",
        "attribute value: count - percentage\n",
        "            \"\"\".format(col))\n",
        "        attribute_groupby_count =  df.groupby(col)[col].count()\n",
        "        \n",
        "        for key in attribute_groupby_count.keys():\n",
        "            print(\"{}: {}  - {} %\".format(\n",
        "                key,\n",
        "                attribute_groupby_count[key],\n",
        "                round(((attribute_groupby_count[key] / len(df)) * 100),2)\n",
        "            ))\n",
        "        print(\"#\"*50)\n",
        "        print(\"\\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0EwjACsTcfQ"
      },
      "source": [
        "Get_Dataset_Summary(meta_data,30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NeXvl5zvN35"
      },
      "source": [
        "#### Step 2.2.3: Filteration of Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grUhG2f2lDKF"
      },
      "source": [
        "def drop_rows_baed_on_values(data_frame, column, column_value):\n",
        "  data_frame.drop(data_frame[data_frame[column] == column_value].index , axis = 0,  inplace = True)\n",
        "\n",
        "def drop_columns(data_frame, attribute_list):\n",
        "  data_frame.drop(attribute_list, axis = 1,  inplace = True)\n",
        "\n",
        "def replace_null_values(data_frame,column,column_value):\n",
        "  data_frame[column].fillna(column_value, inplace = True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvWWm4oKesAv"
      },
      "source": [
        "drop_columns(meta_data, ['offset', 'RT_PCR_positive', 'intubated', 'intubation_present', 'went_icu', 'in_icu','needed_supplemental_O2', 'extubated',  'pO2_saturation',\n",
        "                         'leukocyte_count', 'neutrophil_count', 'lymphocyte_count', 'doi', 'url',\n",
        "                         'license', 'clinical_notes', 'other_notes', 'Unnamed: 29','temperature', 'survival', 'age', 'location', 'folder'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-u7UoDyx8Ae"
      },
      "source": [
        "meta_data.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybzy4VvHzmcL"
      },
      "source": [
        "replace_null_values(data_frame=meta_data,column='sex',column_value='O')\n",
        "drop_rows_baed_on_values(meta_data,'finding', 'todo')\n",
        "drop_rows_baed_on_values(meta_data,'finding', 'Unknown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9URxAf0c7TK"
      },
      "source": [
        "drop_rows_baed_on_values(meta_data,'modality', 'CT')\n",
        "drop_rows_baed_on_values(meta_data,'view', \"AP Supine\")\n",
        "drop_rows_baed_on_values(meta_data,'view', \"L\")\n",
        "drop_rows_baed_on_values(meta_data,'view', \"AP Erect\")\n",
        "drop_rows_baed_on_values(meta_data,'finding', \"Tuberculosis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI9rnZ2_ki46"
      },
      "source": [
        "Get_Dataset_Summary(meta_data,30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEQ3CsPW2QGI"
      },
      "source": [
        "meta_data.groupby(['modality', 'view', 'finding', 'sex']).agg([ 'count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAFqqTWptCFG"
      },
      "source": [
        "#### Step 2.2.3: Graphical Representation of attributes values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjTSdBIvgXe_"
      },
      "source": [
        "def plot_graph_from_dataframe(data,graph_title,x_axis,y_axis, graph_kind='bar'):\n",
        "\n",
        "  #plot data\n",
        "  fig, ax = plt.subplots(figsize=(15,7))\n",
        "  plt.title(graph_title)\n",
        "  ax.set_xlabel(x_axis)\n",
        "  ax.set_ylabel(y_axis)\n",
        "  ax = data.plot(kind=graph_kind, ax=ax)\n",
        "  for i, v in enumerate(list(data)):\n",
        "    ax.text( i ,v + 1, str(v), color='green', fontweight='bold')\n",
        "\n",
        "def dataframe_group_count(data_frame,group_column,index_column):\n",
        "  return data_frame.groupby([group_column]).count()[index_column]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcY2wXWqSnVB"
      },
      "source": [
        "modality_group_count = dataframe_group_count(meta_data, \"modality\", \"filename\")\n",
        "plot_graph_from_dataframe(modality_group_count,\"Modality Vs Count\", \"Modality\", \"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kdTWewCS1Da"
      },
      "source": [
        "view_group_count = dataframe_group_count(meta_data, \"view\", \"filename\")\n",
        "plot_graph_from_dataframe(view_group_count,\"View Vs Count\", \"View\", \"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o98lF8E9S3Gv"
      },
      "source": [
        "finding_group_count = dataframe_group_count(meta_data, \"finding\", \"filename\")\n",
        "plot_graph_from_dataframe(finding_group_count,\"Finding Vs Count\", \"Finding\", \"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70T2m1SAS4_r"
      },
      "source": [
        "gender_group_count = dataframe_group_count(meta_data, \"sex\", \"filename\")\n",
        "plot_graph_from_dataframe(gender_group_count,\"Gender Vs Count\", \"Gender\", \"Count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebd3Z5KbThr9"
      },
      "source": [
        "#### Step 2.2.4: Save Filter attribute Data into Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvAHvkt2Twk5"
      },
      "source": [
        "def save_final_dataset(data_frame=meta_data,dataset_path=unzip_dataset_path):\n",
        "\n",
        "  count = 1\n",
        "  read_dir = join(dataset_path, \"images\")\n",
        "  if not os.path.isdir(read_dir):\n",
        "    raise ValueError('Invalid directory path => {}'.format(read_dir))\n",
        "    \n",
        "  x_rays = join(DATASET_PATH, 'X-RAY')\n",
        "  if not os.path.isdir(x_rays):\n",
        "    os.makedirs(x_rays, exist_ok=True)\n",
        "\n",
        "  for finding,filename  in itertools.zip_longest(np.array(data_frame['finding']), np.array(data_frame['filename'])):\n",
        "\n",
        "    # Load an color image in grayscale\n",
        "    print('Reading Image {} => {}'.format(count,filename))\n",
        "\n",
        "    img = cv2.imread(join(read_dir,filename),cv2.IMREAD_GRAYSCALE)\n",
        "    if img.size >1 and img.shape != () :\n",
        "      # Image Write\n",
        "      if finding == 'Pneumonia/Viral/COVID-19' :\n",
        "        cv2.imwrite(join(x_rays,'{}-Covid.png'.format(count)),img)\n",
        "      else:\n",
        "        cv2.imwrite(join(x_rays,'{}-Normal.png'.format(count)),img)\n",
        "      count += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fme3C_sbLdp"
      },
      "source": [
        "save_final_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G270NFAKqQM2"
      },
      "source": [
        "#### Step 2.2.4: Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZWrniRQnfyd"
      },
      "source": [
        "def load_data(img_dir_path):\n",
        "\n",
        "  # lists to store data\n",
        "  \n",
        "  data = []\n",
        "  label = []\n",
        "  covid_count = 0\n",
        "  non_covid_count = 0\n",
        "\n",
        "  for file in tqdm(os.listdir(img_dir_path)):\n",
        "    if file.endswith(\"png\"):\n",
        "      img = cv2.imread(img_dir_path + '/' + file)\n",
        "      data.append(img)\n",
        "      if file.find(\"Non\") == -1:\n",
        "        label.append(\"Covid\")\n",
        "        covid_count +=1\n",
        "      else:\n",
        "        label.append(\"Normal\")\n",
        "        non_covid_count +=1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  print(\"\"\"\n",
        "  ----------------------\n",
        "  Summary of Data\n",
        "  ----------------------\n",
        "  Total Images: {}\n",
        "  Covid Image: {} - {} %\n",
        "  Normal Image: {} - {} %\n",
        "\n",
        "  \"\"\".format(len(label),\n",
        "             covid_count,\n",
        "             (covid_count / len(label))*100,\n",
        "             non_covid_count,\n",
        "             (non_covid_count / len(label))*100\n",
        "             ))\n",
        "  return data, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9HYyWvtqWPh"
      },
      "source": [
        "Images, Labels = load_data(XRAY_IMAGES_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxMXPg-lEUwY"
      },
      "source": [
        "#### Step 2.2.5: Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDymbjbJEaqt"
      },
      "source": [
        "#Split Dataset into Train and Test sets\n",
        "train_data, test_data, train_label, test_label = train_test_split(Images, Labels, test_size=0.2, random_state=50)\n",
        "\n",
        "#Split Dataset into Train and Test sets\n",
        "test_data, val_data, test_label, val_label = train_test_split(test_data, test_label, test_size=0.5, random_state=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdTuiIukBOBs"
      },
      "source": [
        "def Calculate_Class_Distribution(labels, titles):\n",
        "  for label,title in  itertools.zip_longest(labels,titles):\n",
        "    \n",
        "    volumes = {'Label':label} \n",
        "    df = pd.DataFrame(volumes) \n",
        "    coivd = df[df['Label'] == \"Covid\"]\n",
        "    non_coivd = df[df['Label'] == \"Normal\"]\n",
        "    print(\"\"\"\n",
        "    ----------------------\n",
        "    Summary of {} Data\n",
        "    ----------------------\n",
        "    Total Images: {}\n",
        "    Covid Image: {} - {} %\n",
        "    Normal Image: {} - {} %\n",
        "    \"\"\".format(title,\n",
        "              len(label),\n",
        "              len(coivd),\n",
        "              (len(coivd) / len(label))*100,\n",
        "              len(non_coivd),\n",
        "              (len(non_coivd) / len(label))*100\n",
        "              ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyaj5waqOSky"
      },
      "source": [
        "Calculate_Class_Distribution([train_label,test_label,val_label],[\"Training\",\"Testing\",\"Validation\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCfEqYV-XddX"
      },
      "source": [
        "#### Step 2.2.5: Save Training, Testing, Validation Split Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-z1p-pASTOk"
      },
      "source": [
        "def save_train_split_dataset(data_lists,label_lists,dir_paths=[TRAINING_FOLDER,TESTING_FOLDER,VALIDATION_FOLDER]):\n",
        "\n",
        "  for data,label,dir_path in itertools.zip_longest(data_lists,label_lists, dir_paths):\n",
        "\n",
        "    count =0\n",
        "\n",
        "    if not os.path.isdir(dir_path):\n",
        "      os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    for img,lbl in tqdm(itertools.zip_longest(data,label)):\n",
        "\n",
        "      if lbl == \"Covid\":\n",
        "        cv2.imwrite(join(dir_path,'{}-Covid.png'.format(count)),img)\n",
        "      else:\n",
        "        cv2.imwrite(join(dir_path,'{}-Normal.png'.format(count)),img)\n",
        "      \n",
        "      count += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bla9Avc5WbLD"
      },
      "source": [
        "save_train_split_dataset([train_data,test_data,val_data],[train_label,test_label,val_label])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwDCKAXTX1uu"
      },
      "source": [
        "## Step 02: Load Training Data, Testing Data and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZA26XEg67ze"
      },
      "source": [
        "def load_data(img_dir_path):\n",
        "\n",
        "  # lists to store data\n",
        "  \n",
        "  data = []\n",
        "  label = []\n",
        "  covid_count = 0\n",
        "  non_covid_count = 0\n",
        "\n",
        "  for file in tqdm(os.listdir(img_dir_path)):\n",
        "    if file.endswith(\"png\"):\n",
        "      img = cv2.imread(img_dir_path + '/' + file)\n",
        "      data.append(img)\n",
        "      if file.find(\"Normal\") == -1:\n",
        "        label.append(\"Covid\")\n",
        "        covid_count +=1\n",
        "      else:\n",
        "        label.append(\"Normal\")\n",
        "        non_covid_count +=1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "\n",
        "  return data, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzCLsVfdnlBZ"
      },
      "source": [
        "### Step 2.1: Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpM0XWIOtQJ1"
      },
      "source": [
        "training_data, training_label = load_data(TRAINING_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap_Qd1EZ9mvK"
      },
      "source": [
        "### Step 2.2: Load Validtion Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4JZgo2E9qwW"
      },
      "source": [
        "validation_data, validation_label = load_data(VALIDATION_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h7G-ArU9xAv"
      },
      "source": [
        "### Step 2.3: Load Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUUU-thJ9vRj"
      },
      "source": [
        "testing_data, testing_label = load_data(TESTING_FOLDER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKcv72z8wM5I"
      },
      "source": [
        "## Step 03: Understand and Pre-process Training Data, Testing Data and Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tB-3Nay-Mw7"
      },
      "source": [
        "### Step 3.1: Understand Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJHXZlRAazuV"
      },
      "source": [
        "def plot_images(images, labels,x_axis=2, y_axis=3, classes=None):\n",
        "    \n",
        "    if len(images) == 0:\n",
        "        print(\"no images to show\")\n",
        "        return \n",
        "    else:\n",
        "        random_indices = my_random.sample(range(len(images)), min(len(images), x_axis*y_axis))\n",
        "        \n",
        "    images, labels  = zip(*[(images[i], labels[i]) for i in random_indices])\n",
        "    \n",
        "    # Create figure with 3x3 sub-plots.\n",
        "    fig, axes = plt.subplots(x_axis, y_axis)\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Plot image.\n",
        "        ax.imshow(images[i],cmap='gray' )\n",
        "        if classes is not None:\n",
        "          xlabel = \"Label: {0}\".format(classes[labels[i]])\n",
        "        else:\n",
        "          xlabel = \"Label: {0}\".format(labels[i])\n",
        "\n",
        "        # Show the classes as the label on the x-axis.\n",
        "        ax.set_xlabel(xlabel)\n",
        "        \n",
        "        # Remove ticks from the plot.\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    # Ensure the plot is shown correctly with multiple plots\n",
        "    # in a single Notebook cell.\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9T1K_Q2uixE"
      },
      "source": [
        "print(\"\"\"\n",
        "\n",
        "Training Instane = {}\n",
        "Covid Instane = {}\n",
        "Normal Instance = {}\n",
        "Training Labels = {}\n",
        "\n",
        "----------------------------\n",
        "Training Images with Labels\n",
        "----------------------------\n",
        "\"\"\".format(\n",
        "    len(training_data),\n",
        "    sum(list(map(lambda x: x == \"Covid\", training_label))) ,\n",
        "    sum(list(map(lambda x: x == \"Normal\", training_label))),\n",
        "    training_label\n",
        "    ))\n",
        "\n",
        "plot_images(images=training_data, labels=training_label)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_08KPpP-MUG"
      },
      "source": [
        "### Step 3.2: Understand Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtTvsHHn-Wsg"
      },
      "source": [
        "print(\"\"\"\n",
        "\n",
        "Validation Instane = {}\n",
        "Covid Instane = {}\n",
        "Normal Instance = {}\n",
        "Validation Labels = {}\n",
        "\n",
        "-----------------------------\n",
        "Validation Images with Labels\n",
        "-----------------------------\n",
        "\"\"\".format(\n",
        "    len(validation_data),\n",
        "    sum(list(map(lambda x: x == \"Covid\", validation_label))) ,\n",
        "    sum(list(map(lambda x: x == \"Normal\", validation_label))),\n",
        "    validation_label\n",
        "    ))\n",
        "\n",
        "plot_images(images=validation_data, labels=validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yCXONJ--XTm"
      },
      "source": [
        "### Step 3.3: Understand Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTtkXWnD-rnH"
      },
      "source": [
        "print(\"\"\"\n",
        "\n",
        "Testing Instane = {}\n",
        "Covid Instane = {}\n",
        "Normal Instance = {}\n",
        "Testing Labels = {}\n",
        "\n",
        "---------------------------\n",
        "Testing Images with Labels\n",
        "---------------------------\n",
        "\"\"\".format(\n",
        "    len(testing_data),\n",
        "    sum(list(map(lambda x: x == \"Covid\", testing_label))) ,\n",
        "    sum(list(map(lambda x: x == \"Normal\", testing_label))),\n",
        "    testing_label\n",
        "    ))\n",
        "\n",
        "plot_images(images=testing_data, labels=testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCLOggS8-XyE"
      },
      "source": [
        "### Step 3.4: Pre-process Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK7E5Tjh_cbU"
      },
      "source": [
        "def resize_data(dataset_name,image_list,image_label, Dataset_Path=DATASET_PATH):\n",
        "  \n",
        "  if not os.path.isdir(Dataset_Path):\n",
        "    raise ValueError('Invalid Dataset Directory Path => {}'.format(Dataset_Path))\n",
        "  \n",
        "  resized_img_directory = join(Dataset_Path,\"Resized_{}\".format(dataset_name))\n",
        "  if not os.path.isdir(resized_img_directory):\n",
        "    print(\"Creating Directory => {}\".format(resized_img_directory))\n",
        "    os.makedirs(resized_img_directory, exist_ok=True)\n",
        "  else:\n",
        "    print(\"Accessing Directory => {}\".format(resized_img_directory))\n",
        "    os.listdir(resized_img_directory)\n",
        "\n",
        "  # lists to store data\n",
        "  data = []\n",
        "  count = 1\n",
        "  print(\"Total Images to reiszed is = {}\".format(len(image_list)))\n",
        "  for (x,y) in itertools.zip_longest(np.array(image_list), np.array(image_label)):\n",
        "    img = cv2.resize(x, IMG_DIM, interpolation = cv2.INTER_AREA)\n",
        "    data.append(img)\n",
        "    img_path = join(resized_img_directory, \"{}-{}.png\".format(y,count))\n",
        "    print(\"Saving Resized Image => {}\".format(img_path))\n",
        "    cv2.imwrite(img_path, img) \n",
        "    count += 1\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nopUR5AatSgR"
      },
      "source": [
        "def color_to_grayscale_data(dataset_name,image_list,image_label, Dataset_Path=DATASET_PATH):\n",
        "  \n",
        "  if not os.path.isdir(Dataset_Path):\n",
        "    raise ValueError('Invalid Dataset Directory Path => {}'.format(Dataset_Path))\n",
        "  \n",
        "  grayscale_img_directory = join(Dataset_Path,\"Grayscale_{}\".format(dataset_name))\n",
        "  if not os.path.isdir(grayscale_img_directory):\n",
        "    print(\"Creating Directory => {}\".format(grayscale_img_directory))\n",
        "    os.makedirs(grayscale_img_directory, exist_ok=True)\n",
        "  else:\n",
        "    print(\"Accessing Directory => {}\".format(grayscale_img_directory))\n",
        "\n",
        "  # lists to store data\n",
        "  data = []\n",
        "  count = 1\n",
        "  print(\"Total Images to grayscale is = {}\".format(len(image_list)))\n",
        "  for (x,y) in itertools.zip_longest(np.array(image_list), np.array(image_label)):\n",
        "    img = array_to_img(x)\n",
        "    gray = cv2.cvtColor(np.float32(img), cv2.COLOR_BGR2GRAY)\n",
        "    data.append(gray)\n",
        "    img_path = join(grayscale_img_directory, \"{}-{}.png\".format(y,count))\n",
        "    print(\"Saving Grayscale Image => {}\".format(img_path))\n",
        "    cv2.imwrite(img_path, gray) \n",
        "    count += 1\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92zzWoiC_ZOz"
      },
      "source": [
        "#### Step 3.4.1: Resize X-ray Images in Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw_LKqwZPb0K"
      },
      "source": [
        "resized_training_data = resize_data(\"Training_Data\",training_data,training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20LaICg-uPfQ"
      },
      "source": [
        "plot_images(images=resized_training_data, labels=training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLJQHydTtLYU"
      },
      "source": [
        "#### Step 3.4.2: Convert Resized X-ray Images in Training Data into grayscale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHY1AvOztPDC"
      },
      "source": [
        "grayscale_training_data = color_to_grayscale_data(\"Training_Data\",resized_training_data,training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS6pcOgaueS3"
      },
      "source": [
        "plot_images(images=grayscale_training_data, labels=training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gw-npAl_ort"
      },
      "source": [
        "### Step 3.5: Pre-process Testing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnO_LbzM_vGP"
      },
      "source": [
        "#### Step 3.5.1: Resize X-ray Images in Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HCtvssw_xZ9"
      },
      "source": [
        "resized_testing_data = resize_data(\"Testing_Data\",testing_data,testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKAdChCps9Rf"
      },
      "source": [
        "plot_images(images=resized_testing_data, labels=testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jumdc0D62A6Y"
      },
      "source": [
        "#### Step 3.5.2: Convert Resized X-ray Images in Testing Data into grayscale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLYhH0tV2AHa"
      },
      "source": [
        "grayscale_testing_data = color_to_grayscale_data(\"Testing_Data\",resized_testing_data,testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYA2PeEgtCus"
      },
      "source": [
        "plot_images(images=grayscale_testing_data, labels=testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKcwuE1PAA9G"
      },
      "source": [
        "### Step 3.6: Pre-process Validation Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV2xBIMyAHD8"
      },
      "source": [
        "#### Step 3.6.1: Resize X-ray Images in Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV9Do1D6ANJF"
      },
      "source": [
        "resized_validation_data = resize_data(\"Validation_Data\",validation_data,validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfPm75ihtMce"
      },
      "source": [
        "plot_images(images=resized_validation_data, labels=validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KFJM1qANyu"
      },
      "source": [
        "#### Step 3.6.2: Convert Resized X-ray Images in Validation Data into grayscale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdtF2Zvb2N39"
      },
      "source": [
        "grayscale_validation_data = color_to_grayscale_data(\"Validation_Data\",resized_validation_data,validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w4wZACRtaCI"
      },
      "source": [
        "plot_images(images=resized_validation_data, labels=validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52wNGKOuAUjs"
      },
      "source": [
        "## Step 04: Represent Training Data, Testing Data and Validation Data in Numerical Representation (Machine Understandable Format)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB8bTGYWAyEJ"
      },
      "source": [
        "### Step 4.1: Represent Training Data into Machine Understandable Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRPUIHxlm0SQ"
      },
      "source": [
        "def save_numpy_array(dataset_name,image_list,image_label, Dataset_Path=DATASET_PATH):\n",
        "  \n",
        "  if not os.path.isdir(Dataset_Path):\n",
        "    raise ValueError('Invalid Dataset Directory Path => {}'.format(Dataset_Path))\n",
        "  \n",
        "  numpy_array_directory = join(Dataset_Path,\"{}\".format(dataset_name))\n",
        "  if not os.path.isdir(numpy_array_directory):\n",
        "    print(\"Creating Directory => {}\".format(numpy_array_directory))\n",
        "    os.makedirs(numpy_array_directory, exist_ok=True)\n",
        "  else:\n",
        "    print(\"Accessing Directory => {}\".format(numpy_array_directory))\n",
        "    os.listdir(numpy_array_directory)\n",
        "\n",
        "  # lists to store data\n",
        "  data = []\n",
        "  count = 1\n",
        "\n",
        "\n",
        "  print(\"Total Images convert to numpy array are = {}\".format(len(image_list)))\n",
        "  for (x,y) in itertools.zip_longest(image_list, np.array(image_label)):\n",
        "    array_path = join(numpy_array_directory, \"{}-{}\".format(y,count))\n",
        "    print(\"\"\"\n",
        "    ##########################################################################\n",
        "    Reading Array of Image '{}'\n",
        "\n",
        "    {}\n",
        "\n",
        "    Saving Numpy Array => {}.npy\n",
        "    ##########################################################################\n",
        "    \"\"\".format(\n",
        "        \"{}-{}\".format(y,count),\n",
        "        x,\n",
        "        array_path))\n",
        "    np.save(array_path, x) \n",
        "    count += 1\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POSnYaIJMnpx"
      },
      "source": [
        "def save_array_to_csv(file_name,image_list,image_label, Dataset_Path=DATASET_PATH):\n",
        "  \n",
        "  image_data = {'Image':image_list, \n",
        "                'Label':image_label} \n",
        "                \n",
        "  df = pd.DataFrame(image_data) \n",
        "\n",
        "  path_to_save=join(Dataset_Path,\"{}.csv\".format(file_name))\n",
        "\n",
        "  print(\"\"\"\n",
        "  Saving Image Array with Label of {} => {}\n",
        "  \"\"\".format(file_name,\n",
        "             path_to_save))\n",
        "  \n",
        "  df.to_csv(path_to_save, encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tks-Vx41A26i"
      },
      "source": [
        "#### Step 4.1.1: Convert Resized Grayscale X-ray Images in Training Data into Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28GKvh1NA-Pm"
      },
      "source": [
        "numpy_array_training_data = np.array(grayscale_training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-9SVp1lRjho"
      },
      "source": [
        "save_array_to_csv(\"Numpy_Array_Training_Data\",list(numpy_array_training_data), training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiuOyliyRg-o"
      },
      "source": [
        "save_numpy_array(\"Numpy_Array_Training_Data\",numpy_array_training_data, training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmbgk_UJA-vi"
      },
      "source": [
        "#### Step 4.1.2: Nomalize Numpy Array of Grayscale X-ray Images in Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdkgqosZBFwk"
      },
      "source": [
        "normalized_training_data = numpy_array_training_data / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQFfc-YWR60x"
      },
      "source": [
        "save_array_to_csv(\"Normalized_Array_Training_Data\",list(normalized_training_data), training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRnA3r5SSBQp"
      },
      "source": [
        "save_numpy_array(\"Normalized_Array_Training_Data\",normalized_training_data, training_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGsa3JpsBGKb"
      },
      "source": [
        "### Step 4.2: Represent Testing Data into Machine Understandable Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnDy9VPBMUc"
      },
      "source": [
        "#### Step 4.2.1: Convert Resized Grayscale X-ray Images in Testing Data into Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZDz4wGqBQqn"
      },
      "source": [
        "numpy_array_testing_data = np.array(grayscale_testing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YveVPlf8TaIa"
      },
      "source": [
        "save_array_to_csv(\"Numpy_Array_Testing_Data\",list(numpy_array_testing_data), testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCYezHhUTgXG"
      },
      "source": [
        "save_numpy_array(\"Numpy_Array_Testing_Data\",numpy_array_testing_data, testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slhYuMIrBREr"
      },
      "source": [
        "#### Step 4.2.2: Nomalize Numpy Array of Grayscale X-ray Images in Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWqVfDbD5fKB"
      },
      "source": [
        "normalized_testing_data = numpy_array_testing_data / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxKyjKAxVC_K"
      },
      "source": [
        "save_array_to_csv(\"Normalized_Array_Testing_Data\",list(normalized_testing_data), testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTuKpti_VFkm"
      },
      "source": [
        "save_numpy_array(\"Normalized_Array_Testing_Data\",normalized_testing_data, testing_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNsIqoaa5sO8"
      },
      "source": [
        "### Step 4.3: Represent Validation Data into Machine Understandable Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mk0ooYI5vvY"
      },
      "source": [
        "#### Step 4.3.1: Convert Resized Grayscale X-ray Images in Validation Data into Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QMDG0zi5zRn"
      },
      "source": [
        "numpy_array_validation_data = np.array(grayscale_validation_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zrt6DHuYwRH"
      },
      "source": [
        "save_array_to_csv(\"Numpy_Array_Validation_Data\",list(numpy_array_validation_data), validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMi4z2y3Y0qF"
      },
      "source": [
        "save_numpy_array(\"Numpy_Array_Validation_Data\",numpy_array_validation_data, validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg9NFk9u5zxH"
      },
      "source": [
        "#### Step 4.3.2: Nomalize Numpy Array of Grayscale X-ray Images in Validation Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCiy9mpj55z1"
      },
      "source": [
        "normalized_validation_data = numpy_array_validation_data / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql13DZiPXH26"
      },
      "source": [
        "save_array_to_csv(\"Normalized_Array_Validation_Data\",list(normalized_validation_data), validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Qv4K1MXQ9A"
      },
      "source": [
        "save_numpy_array(\"Normalized_Array_Validation_Data\",normalized_validation_data, validation_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuUREJLMnaJr"
      },
      "source": [
        "### Step 4.4: Reshape Training, Validation & Testing data and Label Encoding of Training, Validation & Testing data label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o_OGVu8pSzI"
      },
      "source": [
        "#### Reshape Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMUc3277793L"
      },
      "source": [
        "input_training_data = normalized_training_data.reshape(-1,IMG_WIDTH,IMG_HEIGHT,1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCv7tZo9pZLY"
      },
      "source": [
        "#### Label Encoding of Training label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd3IX9u0pg8v"
      },
      "source": [
        "encoded_training_label = np.array(LabelEncoder().fit_transform(training_label).astype(int32)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwdfOw5vsWQ8"
      },
      "source": [
        "#### One Hot Encoding of Training label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bipxpGXWpd6k"
      },
      "source": [
        "output_training_label = to_categorical(encoded_training_label).astype('float32')\n",
        "output_training_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6tSt4D5pjlX"
      },
      "source": [
        "#### Reshape Validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7EA2PTapnrW"
      },
      "source": [
        "input_validation_data = normalized_validation_data.reshape(-1,IMG_WIDTH,IMG_HEIGHT,1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nb5J-Fvpofs"
      },
      "source": [
        "#### Label Encoding of Validation label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pba4DM4px5s"
      },
      "source": [
        "encoded_validation_label = np.array(LabelEncoder().fit_transform(validation_label).astype(int32)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrkQlTxstt_e"
      },
      "source": [
        "#### One Hot Encoding of Validation label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF9DOlyytUjt"
      },
      "source": [
        "output_validation_label = to_categorical(encoded_validation_label).astype('float32')\n",
        "output_validation_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRCJA1dMp0fz"
      },
      "source": [
        "#### Reshape Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEUbQqAhp5HG"
      },
      "source": [
        "input_testing_data = normalized_testing_data.reshape(-1,IMG_WIDTH,IMG_HEIGHT,1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRTs8_m8p5xY"
      },
      "source": [
        "#### Label Encoding of Testing label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQfHMyI-qGex"
      },
      "source": [
        "encoded_testing_label = np.array(LabelEncoder().fit_transform(testing_label).astype(int32)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9faFfHMxt_3J"
      },
      "source": [
        "#### One Hot Encoding of Testing label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee0Wegezt-tk"
      },
      "source": [
        "\n",
        "output_testing_label = to_categorical(encoded_testing_label).astype('float32')\n",
        "output_testing_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrrGH_INuZLF"
      },
      "source": [
        "print(\"\"\"\n",
        "***** Dataset Summery *****\n",
        "\n",
        "Training  ==> Image Shape = {0}           Label Shape = {1}         Image Shape = {2}           Label Shape = {3} \n",
        "Test      ==> Image Shape = {4}           Label Shape = {5}         Image Shape = {6}           Label Shape = {7} \n",
        "Validate  ==> Image Shape = {8}           Label Shape = {9}         Image Shape = {10}           Label Shape = {11} \n",
        "\n",
        "\"\"\".format(input_training_data.shape, output_training_label.shape,input_training_data.dtype, output_training_label.dtype,\n",
        "           input_testing_data.shape, output_testing_label.shape,input_testing_data.dtype, output_testing_label.dtype,\n",
        "          input_validation_data.shape,output_validation_label.shape,input_validation_data.dtype,output_validation_label.dtype))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXq148JL7Yn8"
      },
      "source": [
        "## Step 05: Execute the Training Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIccHT0gwc9c"
      },
      "source": [
        "### Steps For CNN Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWfCEXSe7fFV"
      },
      "source": [
        "#### Step 5.1: Create CNN Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW8HSJgI7pxm"
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (IMG_WIDTH,IMG_HEIGHT,1), strides=(1,1), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(64, (3, 3), strides=(2,2), padding='valid', activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2), padding='valid'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# # Adding a third convolutional layer\n",
        "# classifier.add(Conv2D(128, (3, 3), strides=(2,2), padding='valid', activation = 'relu'))\n",
        "# classifier.add(MaxPooling2D(pool_size = (2, 2), padding='valid'))\n",
        "# classifier.add(BatchNormalization())\n",
        "\n",
        "# # Adding a fourth convolutional layer\n",
        "# classifier.add(Conv2D(128, (3, 3), strides=(2,2), padding='valid', activation = 'relu'))\n",
        "# classifier.add(MaxPooling2D(pool_size = (2, 2), padding='valid'))\n",
        "# classifier.add(BatchNormalization())\n",
        "\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection\n",
        "# classifier.add(Dense(units = 64, activation = 'relu'))\n",
        "classifier.add(Dense(units =2 , activation = 'softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSu46MFF-eUT"
      },
      "source": [
        "\n",
        "\n",
        "#### Step 5.2: Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2BCWD3tYyxJ"
      },
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = OPTIMIZER, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD74L88W-bfe"
      },
      "source": [
        "#### Step 5.3: Display Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhomJLm_Y78"
      },
      "source": [
        "# Display Model Achitecture\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg0AcrkP_cPA"
      },
      "source": [
        "#### Step 5.4: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDpVDZc0LEwo"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "mc = ModelCheckpoint(join(MODEL_PATH,'CNN_Best_Model.h5'), monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "history = classifier.fit(input_training_data, output_training_label, \n",
        "                         validation_data=(input_validation_data, output_validation_label), \n",
        "                         epochs=100, \n",
        "                         batch_size= 20,\n",
        "                         callbacks=[es,mc])\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# train_gen = ImageDataGenerator(\n",
        "#         rotation_range = 90,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "#         zoom_range = 0.2, # Randomly zoom image \n",
        "#         horizontal_flip = True\n",
        "#         )  # randomly flip images\n",
        "\n",
        "\n",
        "# train_gen.fit(input_training_data)\n",
        "\n",
        "# history = classifier.fit_generator(train_gen.flow(input_training_data,output_training_label, batch_size = 20),\n",
        "#                          steps_per_epoch=len(input_training_data) / 20,\n",
        "#                          epochs=18)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBJDQash_zPJ"
      },
      "source": [
        "#### Step 5.5: Save  Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yptC_6baY9oE"
      },
      "source": [
        "classifier.save(join(MODEL_PATH, \"CNN_64_cross_76_good.h5\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZyBK-xYwrHY"
      },
      "source": [
        "### Steps For Capsule Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLWB5X82YGnL"
      },
      "source": [
        "#### Step 5.1: Create Capsule Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq00sx2iybPi"
      },
      "source": [
        "def CapsNet(input_shape,n_class,n_routing):\n",
        "\n",
        "  x = Input(shape=input_shape)\n",
        "  conv1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "  #n_vector  => dimensions \n",
        "  #n_channel = “Component Capsules” \n",
        "  primary_capsule = PrimaryCapsule( n_vector=8, n_channel=32, n_kernel_size=9, n_stride=2)(conv1)\n",
        "  digit_capsule = CapsuleLayer( n_capsule=n_class, n_vec=16, n_routing=n_routing, name='digit_capsule')(primary_capsule)\n",
        "  output_capsule = LengthLayer(name='output_capsule')(digit_capsule)\n",
        "\n",
        "\n",
        "  # mask_input = Input(shape=(n_class, ))\n",
        "  # mask = MaskingLayer()([digit_capsule, mask_input])  # two inputs\n",
        "  # dec = Dense(512, activation='relu')(mask)\n",
        "  # dec = Dense(1024, activation='relu')(dec)\n",
        "  # dec = Dense(np.prod(input_shape), activation='softmax')(dec)\n",
        "  # dec = Reshape(input_shape)(dec)\n",
        "\n",
        "  # d = Flatten(name='flatten')(output_capsule)\n",
        "  # d = Dense(512, activation='relu', name='fc1')(d)\n",
        "  # d = Dense(1024, activation='relu', name='fc2')(d)\n",
        "  # d = Dense(1, activation='sigmoid', name='fc3')(d)\n",
        "\n",
        "  # model = Model(x, output_capsule)\n",
        "  model= Model(x, output_capsule)\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqk7azOvYuRc"
      },
      "source": [
        "#### Step 5.2: Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GLFM2Y0Y2HL"
      },
      "source": [
        "input_shape = INPUT_SHAPE\n",
        "n_class = output_training_label.shape[1]\n",
        "n_routing = NUM_ROUTING\n",
        "\n",
        "# loss = LOSSES\n",
        "opt = OPTIMIZER\n",
        "\n",
        "epoch = EPOCH\n",
        "batch = TRAINING_BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_0Ha5yLaOPA"
      },
      "source": [
        "#### Step 5.3: Create Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjs1rBJ41Y3q"
      },
      "source": [
        "def margin_loss(y_ground_truth, y_prediction):\n",
        "    _m_plus = 0.9\n",
        "    _m_minus = 0.1\n",
        "    _lambda = 0.5\n",
        "    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D18vi95WaTnG"
      },
      "source": [
        "#### Step 5.4: Create Model Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utwy5g4R2h62"
      },
      "source": [
        "cap_model = CapsNet(input_shape, n_class=2, n_routing=n_routing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnFR2LH-ab8M"
      },
      "source": [
        "#### Step 5.5: Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLsSTKOV204Y"
      },
      "source": [
        "cap_model.compile(\n",
        "    optimizer=SGD(lr=1e-4, momentum=0.9), \n",
        "    loss=margin_loss ,\n",
        "    metrics=[ margin_loss,'accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15hHrCBYajV2"
      },
      "source": [
        "#### Step 5.6: Display Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_lPrG9MakLP"
      },
      "source": [
        "cap_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hYU9C34as9J"
      },
      "source": [
        "#### Step 5.7: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KGLtdIz8S1k"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "mc = ModelCheckpoint(join(MODEL_PATH,'Capsule_Best_Model.h5'), monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "\n",
        "\n",
        "history = cap_model.fit(input_training_data, output_training_label, \n",
        "              batch_size= batch, \n",
        "              epochs=10, \n",
        "              validation_data=(input_validation_data, output_validation_label), callbacks=[es,mc])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxuobQoma4ED"
      },
      "source": [
        "#### Step 5.8: Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96yWGymWa4Z7"
      },
      "source": [
        "cap_model.save(join(MODEL_PATH, \"Capsule_Best_Model.h5\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNURUX2LAwQS"
      },
      "source": [
        "## Step 06: Execute the Testing Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGeI_jJurzF5"
      },
      "source": [
        "###\tSteps For CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sksDBNy7A1HI"
      },
      "source": [
        "####\tStep 6.1: Load CNN Saved Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6WEXxo9AvIQ"
      },
      "source": [
        "model = load_model(join(MODEL_PATH, \"CNN_Best_Model.h5\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJUk5Og1CLT0"
      },
      "source": [
        "#### Step 6.2: Make Predictions on Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "griPbabDBPn_"
      },
      "source": [
        "loss, acc = model.evaluate(input_testing_data, output_testing_label, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFr7u6SFCsA8"
      },
      "source": [
        "#### Step 6.3: Evaluate Performance of Trained Model on Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDaw8YcrDSZ7"
      },
      "source": [
        "##### Step 6.3.1: Calculate Accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec30kRfjDRg6"
      },
      "source": [
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PWGAIWvH_9p"
      },
      "source": [
        "pred = model.predict(input_testing_data)\n",
        "predx = np.argmax(pred, axis=1)\n",
        "actual =  np.argmax(output_testing_label, axis=1)\n",
        "print(predx)\n",
        "print(actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2nZaBjTtlY3"
      },
      "source": [
        "#####\tStep 6.3.2: Draw Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YepzFcfgGQ3R"
      },
      "source": [
        "\"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "  \n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddXxBaQSrVmw"
      },
      "source": [
        "confusion_mtx = confusion_matrix(actual, predx)\n",
        "cm_plot_labels = ['Covid','Normal']\n",
        "cm = plot_confusion_matrix(confusion_mtx, target_names = cm_plot_labels, normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FBGVhJLBGQ"
      },
      "source": [
        "confusion_mtx = confusion_matrix(actual, predx)\n",
        "cm_plot_labels = ['Covid','Normal']\n",
        "cm = plot_confusion_matrix(confusion_mtx, target_names = cm_plot_labels, normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QRLrxmsKiWw"
      },
      "source": [
        "##### Step 6.3.3: Print Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJW6B5zE3cyH"
      },
      "source": [
        "print(classification_report(actual,predx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjU4yCBPCibA"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzzWWbOYsejf"
      },
      "source": [
        "###\tSteps For Capsule Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7KrE3-1rAQK"
      },
      "source": [
        "####\tStep 6.1: Load Saved Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gegILqT-rcAN"
      },
      "source": [
        "test_capsule_model = load_model(join(MODEL_PATH, \"Capsule_Best_Model.h5\"), \n",
        "                                custom_objects={'CapsuleLayer': CapsuleLayer, \n",
        "                                                'MaskingLayer':MaskingLayer,\n",
        "                                                'LengthLayer':LengthLayer ,\n",
        "                                                'tf': tf,\n",
        "                                                'margin_loss':margin_loss})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFPZHw6uMARn"
      },
      "source": [
        "# Evaluation on test dataset\n",
        "test_loss, test_score = test_capsule_model.evaluate(input_testing_data, output_testing_label, batch_size=16)\n",
        "print(\"Loss on test set: \", test_loss)\n",
        "print(\"Accuracy on test set: \", test_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C24buw5Bs8HM"
      },
      "source": [
        "#### Step 6.2: Make Predictions on Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiVkvshtZHDi"
      },
      "source": [
        "# y_pred, x_recon = test_capsule_model.predict([input_testing_data, output_testing_label], batch_size=10)\n",
        "y_pred = test_capsule_model.predict(input_testing_data, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zk0AzqstM78"
      },
      "source": [
        "#### Step 6.3: Evaluate Performance of Trained Model on Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWJfA9ettYCl"
      },
      "source": [
        "##### Step 6.3.1: Calculate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq47GMg2tRZI"
      },
      "source": [
        "class_pred = np.argmax(y_pred, axis=1)\n",
        "class_test = np.argmax(output_testing_label, axis=1)\n",
        "acc = np.sum(class_pred == class_test)/float(output_testing_label.shape[0])*100\n",
        "print('-'*50)\n",
        "print('Test accuracy: {:5.3f}%'.format(acc))\n",
        "print('Test error   : {:5.3f}%'.format((100-acc)))\n",
        "print('-'*50)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VvJpO5-tsaX"
      },
      "source": [
        "#####\tStep 6.3.2: Draw Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Tw1NXCeq-z"
      },
      "source": [
        "\"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "  \n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV2P_3IXttoG"
      },
      "source": [
        "confusion_mtx = confusion_matrix(class_test, class_pred)\n",
        "cm_plot_labels = ['Covid','Normal']\n",
        "cm = plot_confusion_matrix(confusion_mtx, target_names = cm_plot_labels, normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFvfpqTItyU6"
      },
      "source": [
        "##### Step 6.3.3: Print Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucgmq5uGt11k"
      },
      "source": [
        "print(classification_report(class_test,class_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t7aiMbWmib5"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB83cmHqKkPF"
      },
      "source": [
        "## Step 07: Execute the Application Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3P3w064KrK7"
      },
      "source": [
        "### Step 7.1: Take Input (X-ray Image) from User "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vztutQRUaAOq"
      },
      "source": [
        "input_user_test_image = cv2.imread(TEST_IMAGE_PATH_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF8gWR8tbVMg"
      },
      "source": [
        "### Step 7.2: Convert User Input (X-ray Image) into Feature Vector (Exactly Same as Feature Vectors of Training Data, Testing Data and Validation Data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX4U9kH0bYeQ"
      },
      "source": [
        "resize_user_test_image = cv2.resize(input_user_test_image, IMG_DIM, interpolation = cv2.INTER_AREA)\n",
        "grayscale_user_test_image = cv2.cvtColor(np.float32(resize_user_test_image), cv2.COLOR_BGR2GRAY)\n",
        "normalized_user_test_image = grayscale_user_test_image / 255\n",
        "\n",
        "preprocessed_user_test_image = normalized_user_test_image.reshape(-1,IMG_WIDTH,IMG_HEIGHT,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEucjOj4c79Z"
      },
      "source": [
        "### Step 7.3: Make Prediction on Unseen Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBkhRiYkdBKa"
      },
      "source": [
        "#### Step 7.3.1: Load the Model (Saved in Step 5.8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb6zpBvjdLjq"
      },
      "source": [
        "model = load_model(join(MODEL_PATH, \"Capsule.h5\"), \n",
        "                                custom_objects={'CapsuleLayer': CapsuleLayer, \n",
        "                                                'MaskingLayer':MaskingLayer,\n",
        "                                                'LengthLayer':LengthLayer ,\n",
        "                                                'tf': tf,\n",
        "                                                'margin_loss':margin_loss})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axok9HnHd29a"
      },
      "source": [
        "#### Step 7.3.2: Apply Model on Feature Vector of Unseen Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRLgCS-wd5yg"
      },
      "source": [
        "predict = model.predict(preprocessed_user_test_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-BXgH2KeZvq"
      },
      "source": [
        "#### Step 7.3.3: Return Prediction to the User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4YmMak4eYzr"
      },
      "source": [
        "if np.argmax(predict, axis=-1) == 0 :\n",
        "  print(\"\"\"\n",
        "  *====================*\n",
        "  |     Covid          |\n",
        "  *====================*\n",
        "  \"\"\")\n",
        "else:\n",
        "    print(\"\"\"\n",
        "  *====================*\n",
        "  |     Normal         |\n",
        "  *====================*\n",
        "  \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ1mfJd_zu6N"
      },
      "source": [
        "# Step 9: Execute the Feedback Phase\n",
        "## A Two-Step Process\n",
        "### Step 01: After some time, take Feedback from\n",
        "    o\tDomain Experts and Users on deployed Covid-19 Prediction System\n",
        "### Step 02: Make a List of Possible Improvements based on Feedback received"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyrY2cd_zyPg"
      },
      "source": [
        "# Step 10: Improve Model based on Feedback\n",
        "### There is Always Room for Improvement\n",
        "### Based on Feedback from Domain Experts and Users\n",
        "    o\tImprove your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpmgv53Oz3Ga"
      },
      "source": [
        "<br><br><br>\n",
        "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
        "<center> <h3 style=\"color:green\">JAZAK ALLAH KHAIR</h3> \n",
        "<center> <h3 style=\"color:blue\">==========================================================</h3> </center>\n",
        "<br><br><br>"
      ]
    }
  ]
}